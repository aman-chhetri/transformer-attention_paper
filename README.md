# Attention Is All You Need Paper Implementation

This is my from-scratch implementation of the original transformer architecture from the following paper: [Vaswani, Ashish, et al. "Attention is all you need." Advances in neural information processing systems. 2017.](https://arxiv.org/abs/1706.03762)

<a href=https://arxiv.org/pdf/1706.03762.pdf>
  <p align="center">
    <img width="540" height="700" src="/assets/banner_paper.jpg">
  </p>
</a>